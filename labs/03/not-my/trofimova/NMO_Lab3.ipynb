{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия блокнота \"\"practice_convnet_cifar10.ipynb\"\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmkK3B_LVS4t"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqJ9IpyWVS4w"
      },
      "source": [
        "<h2 style=\"text-align: center;\"><b>Свёрточные нейронные сети: CIFAR10</b></h3>\n",
        "\n",
        "Выполнила: Трофимова Екатерина Александровна, 20223"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZB1i5htVS4x"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxzN34GXyxDt"
      },
      "source": [
        "### Теория CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNQJ_TgsVS4y"
      },
      "source": [
        "В этом ноутбке мы посмотрим, насколько хорошо CNN будут предсказывать классы на более сложном датасете картинок -- CIFAR10. \n",
        "\n",
        "**Внимание:** Рассматривается ***задача классификации изображений***.\n",
        "\n",
        "***Свёрточная нейросеть (Convolutional Neural Network, CNN)*** - это многослойная нейросеть, имеющая в своей архитектуре помимо *полносвязных слоёв* (а иногда их может и не быть) ещё и **свёрточные слои (Conv Layers)** и **pooling-слои (Pool Layers)**.  \n",
        "\n",
        "Собственно, название такое эти сети получили потому, что в основе их работы лежит операция **свёртки**.\n",
        "\n",
        "Сразу же стоит сказать, что свёрточные нейросети **были придуманы прежде всего для задач, связанных с изображениями**, следовательно, на вход они тоже \"ожидают\" изображение.\n",
        "\n",
        "* Например, вот так выглядит неглубокая свёрточная нейросеть, имеющая такую архитектуру:  \n",
        "`Input -> Conv 5x5 -> Pool 2x2 -> Conv 5x5 -> Pool 2x2 -> FC -> Output`\n",
        "\n",
        "<img src=\"https://camo.githubusercontent.com/269e3903f62eb2c4d13ac4c9ab979510010f8968/68747470733a2f2f7261772e6769746875622e636f6d2f746176677265656e2f6c616e647573655f636c617373696669636174696f6e2f6d61737465722f66696c652f636e6e2e706e673f7261773d74727565\" width=800, height=600>  \n",
        "  \n",
        "Свёрточные нейросети (простые, есть и намного более продвинутые) почти всегда строятся по следующему правилу:  \n",
        "\n",
        "`INPUT -> [[CONV -> RELU]*N -> POOL?]*M -> [FC -> RELU]*L -> FC`  \n",
        "\n",
        "то есть:  \n",
        "\n",
        "1). ***Входной слой***: batch картинок -- тензор размера `(batch_size, H, W, C)` или `(batch_size, C, H, W)`\n",
        "\n",
        "2). $M$ блоков (M $\\ge$ 0) из свёрток и pooling-ов, причём именно в том порядке, как в формуле выше. Все эти $M$ блоков вместе называют ***feature extractor*** свёрточной нейросети, потому что эта часть сети отвечает непосредственно за формирование новых, более сложных признаков поверх тех, которые подаются (то есть, по аналогии с MLP, мы опять же переходим к новому признаковому пространству, однако здесь оно строится сложнее, чем в обычных многослойных сетях, поскольку используется операция свёртки)  \n",
        "\n",
        "3). $L$ штук FullyConnected-слоёв (с активациями). Эту часть из $L$ FC-слоёв называют ***classificator***, поскольку эти слои отвечают непосредственно за предсказание нужно класса (сейчас рассматривается задача классификации изображений)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o09BQ_MrVS4z"
      },
      "source": [
        "\n",
        "<h3 style=\"text-align: center;\"><b>Свёрточная нейросеть на PyTorch</b></h3>\n",
        "\n",
        "Ешё раз напомним про основные компоненты нейросети:\n",
        "\n",
        "- непосредственно, сама **архитектура** нейросети (сюда входят типы функций активации у каждого нейрона);\n",
        "- начальная **инициализация** весов каждого слоя;\n",
        "- метод **оптимизации** нейросети (сюда ещё входит метод изменения `learning_rate`);\n",
        "- размер **батчей** (`batch_size`);\n",
        "- количетсво **эпох** обучения (`num_epochs`);\n",
        "- **функция потерь** (`loss`);  \n",
        "- тип **регуляризации** нейросети (`weight_decay`, для каждого слоя можно свой);  \n",
        "\n",
        "То, что связано с ***данными и задачей***:  \n",
        "- само **качество** выборки (непротиворечивость, чистота, корректность постановки задачи);  \n",
        "- **размер** выборки;  \n",
        "\n",
        "Так как мы сейчас рассматриваем **архитектуру CNN**, то, помимо этих компонент, в свёрточной нейросети можно настроить следующие вещи:  \n",
        "\n",
        "- (в каждом ConvLayer) **размер фильтров (окна свёртки)** (`kernel_size`)\n",
        "- (в каждом ConvLayer) **количество фильтров** (`out_channels`)  \n",
        "- (в каждом ConvLayer) размер **шага окна свёртки (stride)** (`stride`)  \n",
        "- (в каждом ConvLayer) **тип padding'а** (`padding`)  \n",
        "\n",
        "\n",
        "- (в каждом PoolLayer) **размер окна pooling'a** (`kernel_size`)  \n",
        "- (в каждом PoolLayer) **шаг окна pooling'а** (`stride`)  \n",
        "- (в каждом PoolLayer) **тип pooling'а** (`pool_type`)  \n",
        "- (в каждом PoolLayer) **тип padding'а** (`padding`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbB5RjlYVS40"
      },
      "source": [
        "### CIFAR10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q-XNxf6VS41"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/soumith/ex/gh-pages/assets/cifar10.png\" width=500, height=400>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqx-IrGdVS42"
      },
      "source": [
        "**CIFAR10:** это набор из 60k картинок 32х32х3, 50k которых составляют обучающую выборку, и оставшиеся 10k - тестовую. Классов в этом датасете 10: `'plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXgtzjz5VS43"
      },
      "source": [
        "# !pip install torch torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AQXJkzxVS47"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtnvcfS0VS5C"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='../pytorch_data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='../pytorch_data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGLJPzK5DjiU"
      },
      "source": [
        "trainset.data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSbQ80MZCW84"
      },
      "source": [
        "trainloader.dataset.train_list[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRmesD01VS5H"
      },
      "source": [
        "# случайный индекс от 0 до размера тренировочной выборки\n",
        "i = np.random.randint(low=0, high=50000)\n",
        "\n",
        "plt.imshow(trainloader.dataset.data[i]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I-smSRhVS5M"
      },
      "source": [
        "### CNN для предсказания на CIFAR10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKAxBNF6zuOD"
      },
      "source": [
        "Напишем свёрточную нейросеть для предсказания на CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Na7SmsRpVS5O"
      },
      "source": [
        "# Подключение зависимостей\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm_notebook\n",
        "from torch.optim import lr_scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m19HkPs9olIV"
      },
      "source": [
        "### Вспомогательные функции"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGYb0ean1IJY"
      },
      "source": [
        "# Попытка ускорить вычисления за счет gpu\n",
        "\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCgL9Cnm3EhV"
      },
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grc6GT3o28QC"
      },
      "source": [
        "#trainloader = DeviceDataLoader(trainloader, device)\n",
        "#testloader = DeviceDataLoader(testloader, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvrbQwKYQUWb"
      },
      "source": [
        "# Функция для обучения модели\n",
        "\n",
        "def train(net, epoch_num = 5, learning_rate = 1e-3):\n",
        "\n",
        "  loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "  # динамически изменяем LR\n",
        "  scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=epoch_num)\n",
        "\n",
        "  # итерируемся\n",
        "  for epoch in tqdm_notebook(range(epoch_num)):\n",
        "    \n",
        "    scheduler.step()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, batch in enumerate(tqdm_notebook(trainloader)):\n",
        "        # так получаем текущий батч\n",
        "        X_batch, y_batch = batch\n",
        "\n",
        "        # обнуляем веса\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        y_pred = net(X_batch)\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        # выводим качество каждые 2000 батчей\n",
        "        if i % 2000 == 1999:\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "  print('Обучение закончено')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rijVMxSsRZkA"
      },
      "source": [
        "# Функция для проверки качества\n",
        "\n",
        "def check_accuracy(net):\n",
        "  class_correct = list(0. for i in range(10))\n",
        "  class_total = list(0. for i in range(10))\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        y_pred = net(images)\n",
        "        _, predicted = torch.max(y_pred, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "  avg_accuracy = 0\n",
        "\n",
        "  for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
        "    avg_accuracy += 100 * class_correct[i] / class_total[i]\n",
        "\n",
        "  print('Avg accuracy %2d %%' % (avg_accuracy / 10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpJLKvrTSDG5"
      },
      "source": [
        "# Функция для визуальной проверки результата\n",
        "\n",
        "def visualize_result(net, index):\n",
        "    image = testloader.dataset.data[index]\n",
        "    plt.imshow(image)\n",
        "    \n",
        "    image = transform(image)  # не забудем отмасштабировать!\n",
        "    \n",
        "    y_pred = net(image.view(1, 3, 32, 32))\n",
        "    _, predicted = torch.max(y_pred, 1)\n",
        "    \n",
        "    plt.title(f'Predicted: {classes[predicted.numpy()[0]]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3tMIYtWIfSI"
      },
      "source": [
        "###Базовая архитектура"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SStmnkaDVS5R"
      },
      "source": [
        "class SimpleConvNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        # вызов конструктора класса nn.Module()\n",
        "        super(SimpleConvNet, self).__init__()\n",
        "        # feature extractor\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        # classificator\n",
        "        self.fc1 = nn.Linear(5 * 5 * 16, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 5 * 5 * 16)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd9Bqjr_VS5Y"
      },
      "source": [
        "net = SimpleConvNet()\n",
        "train(net, learning_rate=0.001, epoch_num=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4_QAnQqVS5d"
      },
      "source": [
        "Посмотрим на accuracy на тестовом датасете:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJYGIIK4VS5e"
      },
      "source": [
        "check_accuracy(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ST9SQ9z82jK4"
      },
      "source": [
        "При базовой архитектуре наблюдается средняя точность в районе 64% на 10 эпохах. Минимальная точность класса 44%. Среднее время вычисления на эпоху = 1:10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akn5NOqBVS5l"
      },
      "source": [
        "Проверим работу нейросети визуально (позапускайте ячейку несколько раз):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1COUZ6-JVS5m"
      },
      "source": [
        "i = np.random.randint(low=0, high=10000)\n",
        "visualize_result(net, i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvOz8gpPJcO3"
      },
      "source": [
        "###Эксперименты с числом сверточных слоев и каналов\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9pgIE5h22D9"
      },
      "source": [
        "Попробуем просто добавить новый сверточный слой "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3CbIaXMVS5r"
      },
      "source": [
        "class ConvNet_3CL(nn.Module):\n",
        "    def __init__(self):\n",
        "        # вызов конструктора класса nn.Module()\n",
        "        super(ConvNet_3CL, self).__init__()\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5)\n",
        "        \n",
        "        self.fc1 = nn.Linear(3 * 3 * 32, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 3 * 3 * 32)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUd5NtraVS5y"
      },
      "source": [
        "net = ConvNet_3CL()\n",
        "train(net, learning_rate=0.001, epoch_num=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMoLalcpVS53"
      },
      "source": [
        "check_accuracy(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFNAOmwLeQbM"
      },
      "source": [
        "Добавление еще одного сверточного слоя с малым количеством каналов отрицательно сказалось на качестве обучения (средний результат ухудшился до 61%) и времени обучения. Примерно на 9 эпохе процесс обучения застопорился. Попробуем теперь вернуться к 2м сверточным слоям, но увеличим число каналов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOFcOhC7ecpq"
      },
      "source": [
        "class ConvNet_2Cl(nn.Module):\n",
        "    def __init__(self):\n",
        "        # вызов конструктора класса nn.Module()\n",
        "        super(ConvNet_2Cl, self).__init__()\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5)\n",
        "        \n",
        "        self.fc1 = nn.Linear(5 * 5 * 128, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 5 * 5 * 128)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DByGHuIw5IUK"
      },
      "source": [
        "net = ConvNet_2Cl()\n",
        "train(net, learning_rate=0.001, epoch_num=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgcyvnuLl1At"
      },
      "source": [
        "check_accuracy(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwOFJC6eCFi7"
      },
      "source": [
        "Увеличение числа каналов положительно сказалось на средней точности - 71% против базовых 64%. Но обучение в рамках эпохи теперь идет гораздо дольше. Попробуем одновременно увеличить число сверточных слоев и число каналов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvnM3nEvn5Xu"
      },
      "source": [
        "class ConvNet_3CL_CH(nn.Module):\n",
        "    def __init__(self):\n",
        "        # вызов конструктора класса nn.Module()\n",
        "        super(ConvNet_3CL_CH, self).__init__()\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5)\n",
        "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5)\n",
        "        \n",
        "        self.fc1 = nn.Linear(256, 120) # 1 x 1 x 256\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = x.view(-1, 256)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uO2A2iapVER"
      },
      "source": [
        "net = ConvNet_3CL_CH()\n",
        "train(net, learning_rate=0.001, epoch_num=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uIZimyyu_h5"
      },
      "source": [
        "check_accuracy(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJBRPLSMkYBc"
      },
      "source": [
        "Средняя точность стала чуть ниже - 70% против 71% на двух слоях. При этом сильно возросло время обучения. Теперь попробуем изменить размер ядра свертки для случая с двумя слоями"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OavxaNowKmZL"
      },
      "source": [
        "class ConvNet_2Cl_3KS(nn.Module):\n",
        "    def __init__(self):\n",
        "        # вызов конструктора класса nn.Module()\n",
        "        super(ConvNet_2Cl_3KS, self).__init__()\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        \n",
        "        self.fc1 = nn.Linear(6 * 6 * 128, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 6 * 6 * 128)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dl8RGOfLIqR"
      },
      "source": [
        "net = ConvNet_2Cl_3KS()\n",
        "train(net, learning_rate=0.001, epoch_num=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liMdrMQifwm_"
      },
      "source": [
        "check_accuracy(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqwNMrbEHFaE"
      },
      "source": [
        "Для двух слоев изменение размера ядра свертки не дало существенных изменений. Теперь посмотрим на 3х слоях"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si2jQOsXmmOA"
      },
      "source": [
        "class ConvNet_3CL_CH_3KS(nn.Module):\n",
        "    def __init__(self):\n",
        "        # вызов конструктора класса nn.Module()\n",
        "        super(ConvNet_3CL_CH_3KS, self).__init__()\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3)\n",
        "        \n",
        "        self.fc1 = nn.Linear(2 * 2 * 256, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 2 * 2 * 256)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xQ7xHBHmSKD"
      },
      "source": [
        "net = ConvNet_3CL_CH_3KS()\n",
        "train(net, learning_rate=0.001, epoch_num=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrOIRzdvmsQC"
      },
      "source": [
        "check_accuracy(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0un3umFKm2Q"
      },
      "source": [
        "А вот на 3х слоях уже наблюдается небольшой прирост: 73% против 70%. Минимальная точность возросладо 54%. \n",
        "\n",
        "Добавление слоев и каналов позволило обогатить пространство признаков и улучшить тем самым результат классификации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hATMRpQwfgm5"
      },
      "source": [
        "### Эксперименты с пулингом и нормализацией"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DepAmx6-fm-i"
      },
      "source": [
        "Теперь попробуем поменять тип пулинга с max на avg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCOpeuZKwMH5"
      },
      "source": [
        "class ConvNet_3Cl_3KS_AvgPool(nn.Module):\n",
        "    def __init__(self):\n",
        "        # вызов конструктора класса nn.Module()\n",
        "        super(ConvNet_3Cl_3KS_AvgPool, self).__init__()\n",
        "        \n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3)\n",
        "        \n",
        "        self.fc1 = nn.Linear(2 * 2 * 256, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 2 * 2 * 256)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dzEx6ylzp1e"
      },
      "source": [
        "net = ConvNet_3Cl_3KS_AvgPool()\n",
        "train(net, learning_rate=0.001, epoch_num=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JFWuyFdzsVr"
      },
      "source": [
        "check_accuracy(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mePVN35Sl-DM"
      },
      "source": [
        "Смена типа пулинга с max на avg еще немного улучшила результат: средняя точность 75% против 73%, минимальная - 57% против 54%. Т.е. положение признака оказалось немного важнее его нличия. Попробуем добавить нормализацию"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qin11pgq5Rzx"
      },
      "source": [
        "class ConvNet_3Cl_3KS_AvgPool_BN(nn.Module):\n",
        "    def __init__(self):\n",
        "        # вызов конструктора класса nn.Module()\n",
        "        super(ConvNet_3Cl_3KS_AvgPool_BN, self).__init__()\n",
        "        \n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "        \n",
        "        self.fc1 = nn.Linear(2 * 2 * 256, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn1(F.relu(self.conv1(x)))\n",
        "        x = self.pool(x)\n",
        "        x = self.bn2(F.relu(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "        x = self.bn3(F.relu(self.conv3(x)))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 2 * 2 * 256)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0tjzrIq6Ct0"
      },
      "source": [
        "net = ConvNet_3Cl_3KS_AvgPool_BN()\n",
        "train(net, learning_rate=0.001, epoch_num=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEE1FXTPB5fL"
      },
      "source": [
        "check_accuracy(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrJkJKQ2CBLy"
      },
      "source": [
        "Нормализация не повлияла на результат"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV0pbkw72DpO"
      },
      "source": [
        "### Эксперимент с функцией активации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHXWVknq2EK-"
      },
      "source": [
        "Обычно в качестве функции активации сверточных слоев используют функцию ReLU. Рассматривать функции активации вроде сигмоидной или тангенциальной мы не будем, т.к. они приводят к проблемам с затуханием или увеличением градиентов. Вместо этого попробуем использовать ELU, которая сохраняет преимущества ReLU и помогает избежать проблемы умирающего ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywB_uVQdCTr1"
      },
      "source": [
        "class ConvNet_3Cl_3KS_AvgPool_ELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        # вызов конструктора класса nn.Module()\n",
        "        super(ConvNet_3Cl_3KS_AvgPool_ELU, self).__init__()\n",
        "        \n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3)\n",
        "        \n",
        "        self.fc1 = nn.Linear(2 * 2 * 256, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.elu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.elu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.elu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 2 * 2 * 256)\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4lruJRiEZI1"
      },
      "source": [
        "net = ConvNet_3Cl_3KS_AvgPool_ELU()\n",
        "train(net, learning_rate=0.001, epoch_num=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLV6jFWDEdQH"
      },
      "source": [
        "check_accuracy(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO1CywGVN6df"
      },
      "source": [
        "Несмотря на то, что значение функции потерь теперь меньше, точность тоже упала. ELU не дает нам выигрыша на текущей архитектуре"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIGg08_Lhp55"
      },
      "source": [
        "### Эксперимент с числом полносвязных слоев"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6_JEoCzPRew"
      },
      "source": [
        "Начнем с простого - уберем 1 слой"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0vXR_1COp4B"
      },
      "source": [
        "class ConvNet_3Cl_3KS_AvgPool_2Fl(nn.Module):\n",
        "    def __init__(self):\n",
        "        # вызов конструктора класса nn.Module()\n",
        "        super(ConvNet_3Cl_3KS_AvgPool_2Fl, self).__init__()\n",
        "        \n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3)\n",
        "        \n",
        "        self.fc1 = nn.Linear(2 * 2 * 256, 512)\n",
        "        self.fc3 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.elu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.elu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.elu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 2 * 2 * 256)\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmpuozLLPtVb"
      },
      "source": [
        "net = ConvNet_3Cl_3KS_AvgPool_2Fl()\n",
        "train(net, learning_rate=0.001, epoch_num=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMoJpwoCWfme"
      },
      "source": [
        "check_accuracy(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaOKa8-UPV0W"
      },
      "source": [
        "И наоборот - добавим 1 слой"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBOyjVUvavCh"
      },
      "source": [
        "class ConvNet_3Cl_3KS_AvgPool_4Fl(nn.Module):\n",
        "    def __init__(self):\n",
        "        # вызов конструктора класса nn.Module()\n",
        "        super(ConvNet_3Cl_3KS_AvgPool_4Fl, self).__init__()\n",
        "        \n",
        "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3)\n",
        "        \n",
        "        self.fc1 = nn.Linear(2 * 2 * 256, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.elu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.elu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.elu(self.conv3(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 2 * 2 * 256)\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE8gDw7-bBrN"
      },
      "source": [
        "net = ConvNet_3Cl_3KS_AvgPool_4Fl()\n",
        "train(net, learning_rate=0.001, epoch_num=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yflCPTwfhzZu"
      },
      "source": [
        "check_accuracy(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y95Pc9XN_y7D"
      },
      "source": [
        "В обоих случаях точность классификации снизилась. Для текущей архитектуры оптимальным является наличие 3 линейных слоев"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2a8Wp3BDz8r"
      },
      "source": [
        "### Сильная архитектура, которая уже была (!) в ноутбуке"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujm2iRccVS6B"
      },
      "source": [
        "Попробуем обучить ещё более сильную нейросеть:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuGcK9uwVS6C"
      },
      "source": [
        "class StrongConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        # вызов конструктора класса nn.Module()\n",
        "        super(StrongConvNet, self).__init__()\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=5)\n",
        "        self.bn1 = nn.BatchNorm2d(8)\n",
        "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=1)\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3)\n",
        "        self.bn3 = nn.BatchNorm2d(16)\n",
        "        self.conv4 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=1)\n",
        "        self.bn4 = nn.BatchNorm2d(32)\n",
        "        self.conv5 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
        "        self.bn5 = nn.BatchNorm2d(32)\n",
        "        \n",
        "        self.fc1 = nn.Linear(4 * 4 * 32, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn1(F.relu(self.conv1(x)))\n",
        "        x = self.pool(x)\n",
        "        x = self.bn2(F.relu(self.conv2(x)))\n",
        "        x = self.bn3(F.relu(self.conv3(x)))\n",
        "        x = self.pool(x)\n",
        "        x = self.bn4(F.relu(self.conv4(x)))\n",
        "        x = self.bn5(F.relu(self.conv5(x)))\n",
        "#         print(x.shape)\n",
        "        x = x.view(-1, 4 * 4 * 32)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBpSPH3RVS6I"
      },
      "source": [
        "Обучим:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dGiAuDBMVS6P"
      },
      "source": [
        "net = StrongConvNet()\n",
        "train(net, learning_rate=0.001, epoch_num=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2lPUzf1VS6S"
      },
      "source": [
        "check_accuracy(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziioVipBVS6Z"
      },
      "source": [
        "Посмотрим визуально на работу нейросети:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "KXagscMmVS6a"
      },
      "source": [
        "i = np.random.randint(low=0, high=10000)\n",
        "visualize_result(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_UmKWzrRhtZ"
      },
      "source": [
        "### Лучшая архитектура"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7U07pr4Q4fO"
      },
      "source": [
        "Итого: наилучший результат 75% точности в среднем, максимальной точности в 85% для отдельного класса и минимальной точности в 57% для отдельного класса. Результат был достигнут при 3х сверточных слоях с увеличенным числом каналов и меньшим ядром свертки для получения большего пространства признаков (что приводит также к сильному увеличению времени обучения), с avg пулингом, ReLU в качестве функции активации и 3мя линейными полносвязными слоями в качестве классификатора. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl46YOn9VS6c"
      },
      "source": [
        "Даже обучив более глубокую и прокаченную (BatchNorm, Dropout) нейросеть на этих данных мы видим, что качество нас всё ещё не устраивает, в реальной жизни необходимо ошибаться не больше, чем на 5%, а часто и это уже много. Как же быть, ведь свёрточные нейросети должны хорошо классифицировать изображения?  \n",
        "\n",
        "К сожалению, обучение нейросети с нуля на не очень большой выборке (а здесь она именно такая) часто приводит к переобучению, что плохо сказывается на тестовом качестве.  \n",
        "\n",
        "Для того, чтобы получить более качественную модель, часто **до**обучают сильную нейросеть, обученную на ImageNet, то есть используют технику Transfer Learning. О ней речь пойдёт далее в нашем курсе."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKpCkwdoVS6d"
      },
      "source": [
        "<h3 style=\"text-align: center;\"><b>Полезные ссылки</b></h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIvuXTqGVS6e"
      },
      "source": [
        "1). *Примеры написания нейросетей на PyTorch (официальные туториалы) (на английском): https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#examples  \n",
        "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek6M_VSsVS6e"
      },
      "source": [
        "2). Курс Стэнфорда:  http://cs231n.github.io/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnIpwKGXVS6f"
      },
      "source": [
        "3). Практически исчерпывающая информация по основам свёрточных нейросетей (из cs231n) (на английском):  \n",
        "\n",
        "http://cs231n.github.io/convolutional-networks/  \n",
        "http://cs231n.github.io/understanding-cnn/  \n",
        "http://cs231n.github.io/transfer-learning/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFuto766VS6g"
      },
      "source": [
        "4). Видео о Computer Vision от Andrej Karpathy: https://www.youtube.com/watch?v=u6aEYuemt0M"
      ]
    }
  ]
}